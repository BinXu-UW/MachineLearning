{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1:Take a random 60% samples for training and the rest 40% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 4 columns):\n",
      "pclass    1309 non-null object\n",
      "age       1046 non-null float64\n",
      "sex       1309 non-null object\n",
      "sibsp     1309 non-null int64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 41.0+ KB\n",
      "['age', 'pclass=1st', 'pclass=2nd', 'pclass=3rd', 'sex=female', 'sex=male', 'sibsp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3549: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import  cross_val_score\n",
    "\n",
    "\n",
    "#import pandas as pd\n",
    "titanic = pd.read_csv('D:\\SIT_Class\\EE695Machine Learning\\HW2\\Titanic.csv')\n",
    "#titanic.head()\n",
    "#titanic.info()\n",
    "\n",
    "x = titanic[['pclass','age','sex','sibsp']]\n",
    "y = titanic['survived']\n",
    "fname = ['pclass','age','sex','sibsp']\n",
    "x.info()\n",
    "#print(x['age'].mode())\n",
    "x['age'].fillna(24.0,inplace = True)\n",
    "#x.info()\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.4,random_state = 99)\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer(sparse = False)\n",
    "x_train = vec.fit_transform(x_train.to_dict(orient='record'))\n",
    "print(vec.feature_names_)\n",
    "x_test = vec.fit_transform(x_test.to_dict(orient='record'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step2:Plot the full tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf:DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "\n",
      "\n",
      "Step2:\n",
      "The full tree has been printed out as HW2_BinXu_Step2.png\n"
     ]
    }
   ],
   "source": [
    "#Using decision tree for classification\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "print(\"clf:\" + str(clf))\n",
    "print(\"\\n\")\n",
    "\n",
    "with open(\"Step2.dot\",'w') as f:\n",
    "    f=tree.export_graphviz(clf,out_file=f,\n",
    "                              feature_names = vec.feature_names_,\n",
    "                              class_names = ['Died', 'Survived'],\n",
    "                              rounded = True,\n",
    "                              filled= True )\n",
    "\n",
    "from subprocess import call\n",
    "call(['dot','-T','png','Step2.dot','-o','HW2_BinXu_Step2.png'])\n",
    "print(\"Step2:\")\n",
    "print(\"The full tree has been printed out as HW2_BinXu_Step2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step3:check the performance of the full model: in‐sample and out-of‐sample accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step3:\n",
      "accuracy in sample(training set) : 0.895541401274\n",
      "accuracy out of sample (test set) : 0.75572519084\n",
      "\n",
      "\n",
      "Training set:\n",
      "                 Predicted Fatalities  Predicted Survival\n",
      "True Fatalities                   466                  20\n",
      "True Survival                      62                 237\n",
      "\n",
      "\n",
      "Percent of survivors correctly predicted(on training set):\n",
      "0.792642140468\n",
      "Percent of fatalities correctly predicted(on training set):\n",
      "0.958847736626\n",
      "\n",
      "\n",
      "Test set:\n",
      "                 Predicted Fatalities  Predicted Survival\n",
      "True Fatalities                   276                  47\n",
      "True Survival                      81                 120\n",
      "\n",
      "\n",
      "Percent of survivors correctly predicted(on test set):\n",
      "0.597014925373\n",
      "Percent of fatalities correctly predicted(on test set):\n",
      "0.854489164087\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "#predict test data and train data accuracy\n",
    "y_predict_test = clf.predict(x_test)\n",
    "y_predict_train= clf.predict(x_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Step3:\")\n",
    "print (\"accuracy in sample(training set) : \"+str(accuracy_score(y_train, y_predict_train)))\n",
    "print (\"accuracy out of sample (test set) : \"+str(accuracy_score(y_test, y_predict_test)))\n",
    "print(\"\\n\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#confusion matrix\n",
    "print(\"Training set:\")\n",
    "print(pd.DataFrame(\n",
    "    confusion_matrix(y_train, y_predict_train),\n",
    "    columns=['Predicted Fatalities', 'Predicted Survival'],\n",
    "    index=['True Fatalities', 'True Survival']\n",
    "))\n",
    "print(\"\\n\")\n",
    "a=[]\n",
    "a=confusion_matrix(y_train, y_predict_train)\n",
    "print(\"Percent of survivors correctly predicted(on training set):\")\n",
    "print(a[1][1]/(a[1][1]+a[1][0]))\n",
    "print(\"Percent of fatalities correctly predicted(on training set):\")\n",
    "print(a[0][0]/(a[0][1]+a[0][0]))\n",
    "print(\"\\n\")\n",
    "print(\"Test set:\")\n",
    "print(pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_predict_test),\n",
    "    columns=['Predicted Fatalities', 'Predicted Survival'],\n",
    "    index=['True Fatalities', 'True Survival']\n",
    "))\n",
    "print(\"\\n\")\n",
    "b=[]\n",
    "b=confusion_matrix(y_test, y_predict_test)\n",
    "print(\"Percent of survivors correctly predicted(on test set):\")\n",
    "print(b[1][1]/(b[1][1]+b[1][0]))\n",
    "print(\"Percent of fatalities correctly predicted(on test set):\")\n",
    "print(b[0][0]/(b[0][1]+b[0][0]))\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:0.895541401274\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "y_predict = clf.predict(x_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Accuracy score:\" + str(clf.score(x_train,y_train)))\n",
    "print(\"\\n\")\n",
    "#print(clf.score(x_train,y_train))\n",
    "#print(classification_report(y_predict,y_test))\n",
    "\n",
    "tree.export_graphviz(clf,out_file = 'tree.dot')\n",
    "#from sklearn.model_selection import KFold\n",
    "meanlist =[]\n",
    "def report(grid_scores, n_top=3):\n",
    "    \"\"\"Report top n_top parameters settings, default n_top=3.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    grid_scores -- output from grid or random search\n",
    "    n_top -- how many to report, of top models\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    top_params -- [dict] top parameter settings found in\n",
    "                  search\n",
    "    \"\"\"\n",
    "    \n",
    "    top_scores = sorted(grid_scores,\n",
    "                        key=itemgetter(1),\n",
    "                        reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        \n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print((\"Mean validation score: \"\n",
    "               \"{0:.3f} (std: {1:.3f})\").format(\n",
    "               score.mean_validation_score,\n",
    "               np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "        meanlist.append(score.mean_validation_score)\n",
    "\n",
    "\n",
    "    return top_scores[0].parameters, meanlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step4:Find the minimum number of misclassification and choose the corresponding tree size to prune the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.792 (std: 0.059)\n",
      "Parameters: {'criterion': 'gini', 'max_depth': None, 'max_leaf_nodes': 2, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.792 (std: 0.059)\n",
      "Parameters: {'criterion': 'gini', 'max_depth': None, 'max_leaf_nodes': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.786 (std: 0.057)\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': None, 'max_leaf_nodes': 4, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.802 (std: 0.048)\n",
      "Parameters: {'criterion': 'gini', 'max_depth': None, 'max_leaf_nodes': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.807 (std: 0.044)\n",
      "Parameters: {'criterion': 'gini', 'max_depth': None, 'max_leaf_nodes': 6, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.809 (std: 0.043)\n",
      "Parameters: {'criterion': 'gini', 'max_depth': None, 'max_leaf_nodes': 7, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.817 (std: 0.042)\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': None, 'max_leaf_nodes': 8, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.817 (std: 0.042)\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': None, 'max_leaf_nodes': 9, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.042)\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': None, 'max_leaf_nodes': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "[0.7919847328244275, 0.7919847328244275, 0.7862595419847328, 0.8015267175572519, 0.8072519083969466, 0.8091603053435115, 0.816793893129771, 0.816793893129771, 0.8148854961832062]\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.042)\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': None, 'max_leaf_nodes': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.815 (std: 0.042)\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': None, 'max_leaf_nodes': 10, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.815 (std: 0.042)\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': 5, 'max_leaf_nodes': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.83      0.83       329\n",
      "          1       0.72      0.74      0.73       195\n",
      "\n",
      "avg / total       0.80      0.79      0.79       524\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRKJSQYiISFQqCBERier/A2IJtrexOEUdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x186648b1828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2,11):\n",
    "    param = {'criterion':['gini','entropy'],\n",
    "             \"min_samples_split\":[2,10,20],\n",
    "             \"max_depth\":[None,2,5,10],\n",
    "             \"min_samples_leaf\":[1,5,10],\n",
    "             \"max_leaf_nodes\": [i]}\n",
    "    grid_search = GridSearchCV(clf,param,cv=10)\n",
    "    grid_search.fit(x_test,y_test)\n",
    "    [best_par,meanlist] = report(grid_search.grid_scores_,1)\n",
    "#    print(grid_search.grid_scores_)\n",
    "print(meanlist)\n",
    "#print(best_par)\n",
    "\n",
    "treesize = [2,3,4,5,6,7,8,9,10]\n",
    "misclass = []\n",
    "for acc in meanlist:\n",
    "    misclass.append((1-acc)*1309*0.6)\n",
    "    \n",
    "\n",
    "good_par = report(grid_search.grid_scores_,3)[0]\n",
    "\n",
    "prune_tree = tree.DecisionTreeClassifier(**good_par)\n",
    "prune_tree.fit(x_train,y_train)\n",
    "tree.export_graphviz(prune_tree,out_file=\"prune.dot\")\n",
    "y_predict_new = prune_tree.predict(x_test)\n",
    "print(classification_report(y_predict_new,y_test))\n",
    "\n",
    "#print(results)\n",
    "import pylab as pl\n",
    "pl.plot(treesize,misclass)\n",
    "pl.xlabel('tree size')\n",
    "pl.ylabel('misclass')\n",
    "pl.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stpe5:Prune the tree with the optimal tree size. Plot the pruned tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step5:\n",
      "The optimal tree has been printed out as HW2_BinXu_Step5.png\n"
     ]
    }
   ],
   "source": [
    "# best tree\n",
    "best_tree=tree.DecisionTreeClassifier(max_leaf_nodes=8,criterion=\"entropy\")\n",
    "best_tree=best_tree.fit(x_train,y_train)\n",
    "\n",
    "#Visulize\n",
    "with open(\"Step5.dot\",'w') as f:\n",
    "    f=tree.export_graphviz(best_tree,out_file=f,\n",
    "                              feature_names =vec.feature_names_,\n",
    "                              class_names = ['Died', 'Survived'],\n",
    "                              rounded = True,\n",
    "                              filled= True )\n",
    "    # graph=graphviz.Source(f)\n",
    "from subprocess import call\n",
    "call(['dot','-T','png','Step5.dot','-o','HW2_BinXu_Step5.png'])\n",
    "print(\"Step5:\")\n",
    "print(\"The optimal tree has been printed out as HW2_BinXu_Step5.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step6:Report as many details as you can on the final pruned tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step6:\n",
      "accuracy in sample(training set) : 0.808917197452\n",
      "accuracy out of sample (test set) : 0.80534351145\n",
      "\n",
      "\n",
      "Training set:\n",
      "                 Predicted Fatalities  Predicted Survival\n",
      "True Fatalities                   416                  70\n",
      "True Survival                      80                 219\n",
      "\n",
      "\n",
      "Percent of survivors correctly predicted(on training set):\n",
      "0.732441471572\n",
      "Percent of fatalities correctly predicted(on training set):\n",
      "0.855967078189\n",
      "\n",
      "\n",
      "Test set:\n",
      "                 Predicted Fatalities  Predicted Survival\n",
      "True Fatalities                   279                  44\n",
      "True Survival                      58                 143\n",
      "\n",
      "\n",
      "Percent of survivors correctly predicted(on test set):\n",
      "0.71144278607\n",
      "Percent of fatalities correctly predicted(on test set):\n",
      "0.863777089783\n"
     ]
    }
   ],
   "source": [
    "y_predict_test2 = best_tree.predict(x_test)\n",
    "y_predict_train2= best_tree.predict(x_train)\n",
    "\n",
    "print(\"Step6:\")\n",
    "print (\"accuracy in sample(training set) : \"+str(accuracy_score(y_train, y_predict_train2)))\n",
    "print (\"accuracy out of sample (test set) : \"+str(accuracy_score(y_test, y_predict_test2)))\n",
    "print(\"\\n\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#confusion matrix\n",
    "print(\"Training set:\")\n",
    "print(pd.DataFrame(\n",
    "    confusion_matrix(y_train, y_predict_train2),\n",
    "    columns=['Predicted Fatalities', 'Predicted Survival'],\n",
    "    index=['True Fatalities', 'True Survival']\n",
    "))\n",
    "print(\"\\n\")\n",
    "a=[]\n",
    "a=confusion_matrix(y_train, y_predict_train2)\n",
    "print(\"Percent of survivors correctly predicted(on training set):\")\n",
    "print(a[1][1]/(a[1][1]+a[1][0]))\n",
    "print(\"Percent of fatalities correctly predicted(on training set):\")\n",
    "print(a[0][0]/(a[0][1]+a[0][0]))\n",
    "print(\"\\n\")\n",
    "print(\"Test set:\")\n",
    "print(pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_predict_test2),\n",
    "    columns=['Predicted Fatalities', 'Predicted Survival'],\n",
    "    index=['True Fatalities', 'True Survival']\n",
    "))\n",
    "print(\"\\n\")\n",
    "b=[]\n",
    "b=confusion_matrix(y_test, y_predict_test2)\n",
    "print(\"Percent of survivors correctly predicted(on test set):\")\n",
    "print(b[1][1]/(b[1][1]+b[1][0]))\n",
    "print(\"Percent of fatalities correctly predicted(on test set):\")\n",
    "print(b[0][0]/(b[0][1]+b[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After pruned the tree the \n",
    "accuracy in sample(training set) : 80.89%\n",
    "accuracy out of sample (test set) : 80.53%\n",
    "\n",
    "By comparing the previous the accuracy\n",
    "accuracy in sample(training set) : 89.55%\n",
    "accuracy out of sample (test set) : 75.57%\n",
    "\n",
    "The accuracy out of sample (test set) is better after pruned the tree(80.53%>75.57%).\n",
    "\n",
    "By using the DecisionTreeClassifier() function, the max_leaf_nodes should be 8 to prune the tree. Because the accuracy out of sample for prune is 81.92%, the highest number.\n",
    "\n",
    "After pruned the tree the :\n",
    "Percent of survivors correctly predicted(on training set): 73.24%\n",
    "Percent of fatalities correctly predicted(on training set):85.59%\n",
    "Percent of survivors correctly predicted(on test set):71.14%\n",
    "Percent of fatalities correctly predicted(on test set):86.37%\n",
    "\n",
    "There is indead an improvement in out of sample for the full tree and the pruned tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
